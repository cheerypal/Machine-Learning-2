C:\Users\euang\AppData\Local\Programs\Python\Python38\python.exe C:/Users/euang/Documents/Year4/supervised-amaan-learning/Decision_Trees/main.py

Running J48 ....

Cross Validation started ....
Start confusion matrix ....
Confusion Matrix:
 [[   0  152   52    6    0    0    0    0    0    0]
 [   0 1200  681  156  177    0    0    0    1    5]
 [   0 1044  579  232  366    0    2    0   27    0]
 [   0  190  335  398  438    0   35    0   13    1]
 [   0  479  532  580  356    0    4    0   29    0]
 [   0   84   23   51   43    0    0    0    9    0]
 [   0   33  103   93  122    0    0    0    7    2]
 [   0  110   61   31   35    0    0    0    3    0]
 [   0  290   96   76   49    0    2    0   27    0]
 [   0  108  100   35    7    0    0    0   20    0]]
C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

               precision    recall  f1-score   support

           0       0.00      0.00      0.00       210
           1       0.33      0.54      0.41      2220
           2       0.23      0.26      0.24      2250
           3       0.24      0.28      0.26      1410
           4       0.22      0.18      0.20      1980
           5       0.00      0.00      0.00       210
           6       0.00      0.00      0.00       360
           7       0.00      0.00      0.00       240
           8       0.20      0.05      0.08       540
           9       0.00      0.00      0.00       270

    accuracy                           0.26      9690
   macro avg       0.12      0.13      0.12      9690
weighted avg       0.22      0.26      0.23      9690


    Average tpr  Average fpr
0     0.500000     0.500000
1     0.555556     0.486486
2     0.577823     0.580889
3     0.615942     0.572577
4     0.613186     0.606734
5     0.500000     0.500000
6     0.665130     0.666667
7     0.500000     0.500000
8     0.662696     0.650000
9     0.666384     0.666667

    ROC Area
0  0.500000
1  0.603604
2  0.495401
3  0.565048
4  0.509678
5  0.500000
6  0.497696
7  0.500000
8  0.519044
9  0.499575

Accuracy: 0.26418988648090813

Plotting Tree ....

Testing using dataset testing data ....

Starting ....

Starting Confusion Matrix ....

Confusion Matrix
 [[  0  40  17   3   0   0   0   0   0   0]
 [  0 548 100  52  17   0   0   0   3   0]
 [  0 272 191 106 173   0   0   0   8   0]
 [  0 110 115  93 129   0   0   0   3   0]
 [  0 145 104 101 310   0   0   0   0   0]
 [  0   9   1   0  31   0   0   0  19   0]
 [  0  49  11  12   2   0   0   0  16   0]
 [  0   7   7  17  26   0   0   0   3   0]
 [  0  82  14  36  11   0   0   0   7   0]
 [  0  64   3  22   1   0   0   0   0   0]]



               precision    recall  f1-score   support

           0       0.00      0.00      0.00        60
           1       0.41      0.76      0.54       720
           2       0.34      0.25      0.29       750
           3       0.21      0.21      0.21       450
           4       0.44      0.47      0.46       660
           5       0.00      0.00      0.00        60
           6       0.00      0.00      0.00        90
           7       0.00      0.00      0.00        60
           8       0.12      0.05      0.07       150
           9       0.00      0.00      0.00        90

    accuracy                           0.37      3090
   macro avg       0.15      0.17      0.16      3090
weighted avg       0.31      0.37      0.33      3090

C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

    Average tpr  Average fpr
0     0.500000     0.500000
1     0.557243     0.412963
2     0.613675     0.581778
3     0.622601     0.597778
4     0.613169     0.510101
5     0.500000     0.500000
6     0.500000     0.500000
7     0.500000     0.500000
8     0.660771     0.651111
9     0.500000     0.500000

    ROC Area
0  0.500000
1  0.716421
2  0.547846
3  0.537235
4  0.654602
5  0.500000
6  0.500000
7  0.500000
8  0.514490
9  0.500000

Accuracy: 0.3718446601941748

Testing using 4000 moved testing data ....

Starting ....

Starting Confusion Matrix ....

Confusion Matrix
 [[  0  76  68   0   5   0   0   0   0   0]
 [  0 954 664   0  35   0   0   0   0   0]
 [  0 791 802   1  67   0   0   0   0   0]
 [  0 396 566   1  70   0   0   0   0   0]
 [  0 600 816   0  61   0   0   0   0   0]
 [  0  37 106   0   3   0   0   0   0   0]
 [  0 109 123   0   7   0   0   0   0   0]
 [  0  73  84   0   4   0   0   0   0   0]
 [  0 197 159   0   7   0   0   0   0   0]
 [  0 108  92   0   8   0   0   0   0   0]]



               precision    recall  f1-score   support

           0       0.00      0.00      0.00       149
           1       0.29      0.58      0.38      1653
C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
           2       0.23      0.48      0.31      1661
           3       0.50      0.00      0.00      1033
           4       0.23      0.04      0.07      1477
           5       0.00      0.00      0.00       146
           6       0.00      0.00      0.00       239
           7       0.00      0.00      0.00       161
           8       0.00      0.00      0.00       363
           9       0.00      0.00      0.00       208

    accuracy                           0.26      7090
   macro avg       0.12      0.11      0.08      7090
weighted avg       0.24      0.26      0.18      7090


    Average tpr  Average fpr
0     0.500000     0.500000
1     0.518600     0.480120
2     0.501785     0.507168
3     0.666557     0.666667
4     0.654103     0.654155
5     0.500000     0.500000
6     0.500000     0.500000
7     0.500000     0.500000
8     0.500000     0.500000
9     0.500000     0.500000

    ROC Area
0  0.500000
1  0.557720
2  0.491925
3  0.499835
4  0.499921
5  0.500000
6  0.500000
7  0.500000
8  0.500000
9  0.500000

Accuracy: 0.2564174894217207

Testing using 9000 moved testing data ....

Starting ....

Starting Confusion Matrix ....

Confusion Matrix
 [[   0   95  129   26    0    0    0    0    0    0]
 [   0 1064 1409  301    3    0    0    0    0    0]
 [   0  978 1517  340   15    0    0    0    0    0]
 [   0  564  980  206    8    0    0    0    0    0]
 [   0  766 1460  274    9    0    0    0    0    0]
 [   0   77  149   21    1    0    0    0    0    0]
 [   0  116  246   66    1    0    0    0    0    0]
 [   0  102  154   24    2    0    0    0    0    0]
 [   0  211  330  112    2    0    0    0    0    0]
 [   0  109  191   32    0    0    0    0    0    0]]


C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

               precision    recall  f1-score   support

           0       0.00      0.00      0.00       250
           1       0.26      0.38      0.31      2777
           2       0.23      0.53      0.32      2850
           3       0.15      0.12      0.13      1758
           4       0.22      0.00      0.01      2509
           5       0.00      0.00      0.00       248
           6       0.00      0.00      0.00       429
           7       0.00      0.00      0.00       282
           8       0.00      0.00      0.00       655
           9       0.00      0.00      0.00       332

    accuracy                           0.23     12090
   macro avg       0.09      0.10      0.08     12090
weighted avg       0.18      0.23      0.17     12090


    Average tpr  Average fpr
0     0.500000     0.500000
1     0.557241     0.543753
2     0.484734     0.488716
3     0.627552     0.630728
4     0.665592     0.665322
5     0.500000     0.500000
6     0.500000     0.500000
7     0.500000     0.500000
8     0.500000     0.500000
9     0.500000     0.500000

    ROC Area
0  0.500000
1  0.520232
2  0.494028
3  0.495235
4  0.500404
5  0.500000
6  0.500000
7  0.500000
8  0.500000
9  0.500000

Accuracy: 0.23126550868486354

Running Random Forrest Classifier ....

Cross Validation started ....
Start confusion matrix ....
Confusion Matrix:
 [[   0  207    3    0    0    0    0    0    0    0]
 [   0 1374  640   73  133    0    0    0    0    0]
 [   0  935  939  152  224    0    0    0    0    0]
 [   0  220  383  369  438    0    0    0    0    0]
 [   0  494  615  252  619    0    0    0    0    0]
 [   0   42  105   18   45    0    0    0    0    0]
 [   0   56  110   55  139    0    0    0    0    0]
 [   0   66  118   31   25    0    0    0    0    0]
 [   0  254  179   51   56    0    0    0    0    0]
 [   0   69  187   10    4    0    0    0    0    0]]

               precision    recall  f1-score   support

           0       0.00      0.00      0.00       210
           1       0.37      0.62      0.46      2220
           2       0.29      0.42      0.34      2250
           3       0.36      0.26      0.30      1410
           4       0.37      0.31      0.34      1980
           5       0.00      0.00      0.00       210
           6       0.00      0.00      0.00       360
           7       0.00      0.00      0.00       240
           8       0.00      0.00      0.00       540
           9       0.00      0.00      0.00       270

    accuracy                           0.34      9690
   macro avg       0.14      0.16      0.14      9690
weighted avg       0.28      0.34      0.30      9690

C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

    Average tpr  Average fpr
0     0.500000     0.500000
1     0.562115     0.460360
2     0.561828     0.527556
3     0.640821     0.579433
4     0.620666     0.562458
5     0.500000     0.500000
6     0.500000     0.500000
7     0.500000     0.500000
8     0.500000     0.500000
9     0.500000     0.500000

    ROC Area
0  0.500000
1  0.652632
2  0.551409
3  0.592083
4  0.587312
5  0.500000
6  0.500000
7  0.500000
8  0.500000
9  0.500000

Accuracy: 0.34066047471620226

Plotting Tree ....

Testing using a dataset testing data ....

Starting ....

Starting Confusion Matrix ....

Confusion Matrix
 [[  0  42  18   0   0   0   0   0   0   0]
 [  0 462 212  11  35   0   0   0   0   0]
 [  0 221 297  66 166   0   0   0   0   0]
 [  0  69 189 125  67   0   0   0   0   0]
 [  0 147 132  72 309   0   0   0   0   0]
 [  0   0  30   0  30   0   0   0   0   0]
 [  0  27  59   4   0   0   0   0   0   0]
 [  0   7  23   0  30   0   0   0   0   0]
 [  0  85  19  15  31   0   0   0   0   0]
 [  0  47  43   0   0   0   0   0   0   0]]



               precision    recall  f1-score   support

           0       0.00      0.00      0.00        60
           1       0.42      0.64      0.51       720
           2       0.29      0.40      0.34       750
           3       0.43      0.28      0.34       450
           4       0.46      0.47      0.47       660
           5       0.00      0.00      0.00        60
           6       0.00      0.00      0.00        90
           7       0.00      0.00      0.00        60
           8       0.00      0.00      0.00       150
           9       0.00      0.00      0.00        90

    accuracy                           0.39      3090
   macro avg       0.16      0.18      0.16      3090
weighted avg       0.33      0.39      0.35      3090

C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

    Average tpr  Average fpr
0     0.500000     0.500000
1     0.575949     0.452778
2     0.563390     0.534667
3     0.645455     0.574074
4     0.617421     0.510606
5     0.500000     0.500000
6     0.500000     0.500000
7     0.500000     0.500000
8     0.500000     0.500000
9     0.500000     0.500000

    ROC Area
0  0.500000
1  0.684757
2  0.543085
3  0.607071
4  0.660223
5  0.500000
6  0.500000
7  0.500000
8  0.500000
9  0.500000

Accuracy: 0.386084142394822

Testing using 4000 moved testing data ....

Starting ....

Starting Confusion Matrix ....

Confusion Matrix
 [[   0   56   91    0    2    0    0    0    0    0]
 [   0  632 1009    0   12    0    0    0    0    0]
 [   0  476 1174    0   11    0    0    0    0    0]
 [   0  222  802    0    9    0    0    0    0    0]
 [   0  348 1114    0   15    0    0    0    0    0]
 [   0   20  125    0    1    0    0    0    0    0]
 [   0   42  176    0   21    0    0    0    0    0]
 [   0   40  121    0    0    0    0    0    0    0]
 [   0  110  246    0    7    0    0    0    0    0]
 [   0   81  123    0    4    0    0    0    0    0]]


C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

               precision    recall  f1-score   support

           0       0.00      0.00      0.00       149
           1       0.31      0.38      0.34      1653
           2       0.24      0.71      0.35      1661
           3       0.00      0.00      0.00      1033
           4       0.18      0.01      0.02      1477
           5       0.00      0.00      0.00       146
           6       0.00      0.00      0.00       239
           7       0.00      0.00      0.00       161
           8       0.00      0.00      0.00       363
           9       0.00      0.00      0.00       208

    accuracy                           0.26      7090
   macro avg       0.07      0.11      0.07      7090
weighted avg       0.17      0.26      0.17      7090


    Average tpr  Average fpr
0     0.500000     0.500000
1     0.581338     0.538755
2     0.433469     0.429311
3     0.500000     0.500000
4     0.663034     0.661975
5     0.500000     0.500000
6     0.500000     0.500000
7     0.500000     0.500000
8     0.500000     0.500000
9     0.500000     0.500000

    ROC Area
0  0.500000
1  0.563875
2  0.506237
3  0.500000
4  0.501589
5  0.500000
6  0.500000
7  0.500000
8  0.500000
9  0.500000

Accuracy: 0.25684062059238366

Testing using 9000 moved testing data ....

Starting ....

Starting Confusion Matrix ....

Confusion Matrix
 [[   0  174   60    3   13    0    0    0    0    0]
 [   0 1997  660   34   86    0    0    0    0    0]
 [   0 2018  707   46   79    0    0    0    0    0]
 [   0 1193  488   32   45    0    0    0    0    0]
 [   0 1659  695   82   73    0    0    0    0    0]
 [   0  154   53   34    7    0    0    0    0    0]
 [   0  297   92   10   30    0    0    0    0    0]
 [   0  211   63    5    3    0    0    0    0    0]
 [   0  432  187   13   23    0    0    0    0    0]
 [   0  221   99    6    6    0    0    0    0    0]]


C:\Users\euang\AppData\Local\Programs\Python\Python38\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

               precision    recall  f1-score   support

           0       0.00      0.00      0.00       250
           1       0.24      0.72      0.36      2777
           2       0.23      0.25      0.24      2850
           3       0.12      0.02      0.03      1758
           4       0.20      0.03      0.05      2509
           5       0.00      0.00      0.00       248
           6       0.00      0.00      0.00       429
           7       0.00      0.00      0.00       282
           8       0.00      0.00      0.00       655
           9       0.00      0.00      0.00       332

    accuracy                           0.23     12090
   macro avg       0.08      0.10      0.07     12090
weighted avg       0.17      0.23      0.15     12090


    Average tpr  Average fpr
0     0.500000     0.500000
1     0.438993     0.427277
2     0.580573     0.582772
3     0.658992     0.661533
4     0.657233     0.654162
5     0.500000     0.500000
6     0.500000     0.500000
7     0.500000     0.500000
8     0.500000     0.500000
9     0.500000     0.500000

    ROC Area
0  0.500000
1  0.517574
2  0.496702
3  0.496189
4  0.504607
5  0.500000
6  0.500000
7  0.500000
8  0.500000
9  0.500000

Accuracy: 0.23234077750206783

Process finished with exit code 0
